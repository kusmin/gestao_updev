# Observabilidade â€“ Plano de ImplementaÃ§Ã£o

## Contexto Atual
- **Logs**: o backend jÃ¡ inicia um `zap.Logger` em `backend/cmd/api/main.go:23` e adiciona `middleware.RequestID` no router, mas a stack ainda usa o `gin.Logger` padrÃ£o (`backend/internal/server/server.go:39`), que imprime em texto simples para `stdout` sem correlaÃ§Ã£o automÃ¡tica com `tenant_id` ou usuÃ¡rio.
- **MÃ©tricas**: nÃ£o existe endpoint `/metrics` nem coleta de mÃ©tricas de aplicaÃ§Ã£o, GC ou banco.
- **Tracing**: nÃ£o hÃ¡ instrumentaÃ§Ã£o OpenTelemetry (`rg` sem ocorrÃªncias), logo nÃ£o Ã© possÃ­vel rastrear chamadas entre serviÃ§os ou medir spans de GORM/Gin.
- **Alertas/Dashboards**: apenas diretrizes genÃ©ricas constam em `docs/operacao-devops.md:44`, sem detalhes de painÃ©is, consultas ou integraÃ§Ãµes com Grafana/Alertmanager.

## Objetivos
1. **Logs estruturados consistentes**: middleware prÃ³prio que envia todas as requisiÃ§Ãµes para o `zap.Logger` com `request_id`, `tenant_id`, `user_id` (quando autenticado), status HTTP, tempo de resposta e tamanho das cargas.
2. **MÃ©tricas exportadas**: expor `/metrics` em Prometheus com counters de requisiÃ§Ãµes, histogramas de latÃªncia, mÃ©tricas de filas (agenda, vendas), alÃ©m de observar GORM (`db_conns`, `queries_failed_total`).
3. **Tracing distribuÃ­do**: habilitar OpenTelemetry (OTLP/HTTP) para Gin, GORM e chamadas HTTP a terceiros, permitindo reconstruir fluxos de reservas e vendas.
4. **PainÃ©is + Alertas**: definir dashboards base na stack Grafana/Loki/Tempo + alertas (latÃªncia p95, taxa de erro 5xx, saturaÃ§Ã£o do DB e filas de inventÃ¡rio) com playbooks associados.

## Arquitetura Proposta
| Camada | Ferramenta | Detalhes |
|--------|------------|----------|
| Logs   | `zap` + `middleware.Logger` â†’ Collector Loki | Middleware escreve JSON consolidado, collector envia para Grafana Cloud (Loki). |
| MÃ©tricas | OpenTelemetry SDK â†’ `otel-collector` â†’ Prometheus/Grafana | Exportador `prometheus` embutido para `/metrics` local + pipeline OTLP para Grafana Cloud. |
| Traces | `otelgin`, `otelgorm`, `otelhttp` â†’ OTLP â†’ Grafana Tempo | Headers W3C (`traceparent`) propagados; contexto herdado pelo middleware de autenticaÃ§Ã£o. |
| Alertas | Grafana Alerting | Regras baseadas nas mÃ©tricas acima; notificaÃ§Ã£o para Slack/Teams. |

### Componentes
1. **SDK OpenTelemetry** (Go): inicializado no `cmd/api/main.go` antes de criar o `zapLogger`, carregando config via env (`OTEL_EXPORTER_OTLP_ENDPOINT`, `OTEL_SERVICE_NAME=gestao-api`).
2. **Middleware de logging**: substitui `gin.Logger()` e usa `zap.Logger` com os campos `request_id`, `tenant_id`, `user_id`, `path`, `method`, `status`, `latency_ms`, `bytes_in`, `bytes_out`.
3. **Collector (docker-compose)**: adicionar serviÃ§o `otel-collector` com pipelines `otlp -> loki` e `otlp -> tempo -> grafana` (para ambientes locais/staging).
4. **Dashboards**: JSON exportado para `docs/grafana/*.json` com painÃ©is â€œVisÃ£o Geral APIâ€, â€œBanco & Fila de Agendaâ€.

### ExecuÃ§Ã£o local
- `.env.example` agora inclui os envs `SERVICE_NAME`, `OTEL_ENABLED`, `OTEL_EXPORTER_OTLP_ENDPOINT`, `OTEL_EXPORTER_OTLP_HEADERS`, `OTEL_EXPORTER_OTLP_INSECURE` e `METRICS_ROUTE`.
- `docker-compose.yml` sobe o `otel-collector` (imagem `otel/opentelemetry-collector-contrib`) usando `docker/otel-collector-config.yaml`, que por padrÃ£o exporta traces/mÃ©tricas para o prÃ³prio log da ferramenta.
- Para inspecionar mÃ©tricas localmente, basta acessar `http://localhost:8080/metrics` (ou o caminho configurado) ou apontar um Prometheus externo com `job_name: gestao-api`.

## Plano de ImplementaÃ§Ã£o
### Fase 1 â€“ Fundamentos de Logging âœ…
- `internal/middleware/logging.go` substitui o `gin.Logger`, emitindo eventos estruturados no `zap`.
- `RequestID` continua sendo a fonte de correlaÃ§Ã£o e Ã© propagado para cada log.

### Fase 2 â€“ MÃ©tricas Prometheus âœ…
- Pacote `pkg/telemetry` inicializa OpenTelemetry (MeterProvider + exporter Prometheus) com atributos `service.name`, `deployment.environment`.
- `/metrics` Ã© exposto no caminho configurÃ¡vel `METRICS_ROUTE` (default `/metrics`) e pronto para scrape Prometheus/Loki.

### Fase 3 â€“ Tracing (em andamento)
- `cmd/api/main.go` inicializa o tracer via OTLP HTTP (configurado pelos envs `OTEL_*`) e injeta o middleware `otelgin`.
- PrÃ³ximos passos: propagar `trace_id` nas respostas HTTP, instrumentar GORM (plugin dedicado), clientes externos e adicionar spans customizados nos casos de uso crÃ­ticos (CreateBooking, CreateSalesOrder).

### Fase 4 â€“ Stack Operacional
1. Estender `docker-compose.yml` com `grafana`, `loki`, `tempo`, `promtail` (perfil `observability`).
2. Versionar dashboards (`docs/grafana/*.json`) e definir pipeline â€œObservability smoke-testsâ€ em CI (verificar `/metrics` e `/healthz`).
3. Configurar alertas iniciais e documentar no runbook (links nos docs devops).

## Backlog / PendÃªncias
- ğŸ§© Definir polÃ­tica de retenÃ§Ã£o para logs/traces (mÃ­nimo 7 dias).
- ğŸ” Garantir redaction de dados sensÃ­veis (token JWT, dados de pagamento) antes de enviar ao collector.
- ğŸ§ª Adicionar testes para middleware de logging (verificar presenÃ§a do `request_id`) e endpoint `/metrics`.
- ğŸ“Š Criar painel â€œFinanceiroâ€ com mÃ©tricas derivadas (faturamento diÃ¡rio) usando PromQL/Recording Rules.
- ğŸ“¥ Avaliar integraÃ§Ã£o com Sentry ou Honeycomb para alertas de erros aplicacionais antes da fase 3.
- ğŸ§± Adicionar exporters reais (Grafana Cloud / Tempo / Loki) no `docker/otel-collector-config.yaml`.

Com este plano, conseguimos iniciar a implementaÃ§Ã£o incremental focando primeiro em visibilidade bÃ¡sica (logs e mÃ©tricas), seguido por tracing e a stack completa de observabilidade/alertas.
